# @package _global_
exp_name: grpo_qwen2_vl-2b_base


# Model arguments
model_name_or_path: models/Qwen2-VL-2B
model_revision: main
torch_dtype: bfloat16
attn_implementation: flash_attention_2
min_pixels: 3136
max_pixels: 501760
freeze_llm: false
freeze_vision: false

# Lora Arguments
# No LoRA is used here

# Data training arguments
dataset_mixer:
  leonardPKU/GEOQA_R1V_Train_8K: 1.0
dataset_splits:
  - train
dataset_configs:
  - default
system_prompt: "A conversation between User and Assistant. The user asks a question about the image, and the Assistant solves it. The assistant first thinks about the reasoning process in the mind and then provides the user with the answer.The reasoning process and answer are enclosed within <think> </think> and <answer> </answer> tags, respectively, i.e., <think> reasoning process here </think><answer> answer here </answer>\nUser: {problem} \nAssistant: Let me solve this step by step.\n"
truncation_side: left
padding_side: left
preprocessing_num_workers: 5
wandb_project: bmir
use_unsloth: false
unsloth_configs:
  max_seq_length: 2048
  load_in_4bit: true
  fast_inference: true
  gpu_memory_utilization: 0.8
  trust_remote_code: true

# GRPO trainer config
output_dir: outputs/geoqa_qwen2_vl-2b_base
overwrite_output_dir: true
bf16: true
max_steps: -1
num_train_epochs: 2
per_device_train_batch_size: 8
gradient_accumulation_steps: 2
gradient_checkpointing: true
gradient_checkpointing_kwargs:
  use_reentrant: false
learning_rate: 1e-6 # 1.0e-6 as in the deepseek math paper 5-e7 from https://hijkzzz.notion.site/unraveling-rlhf-and-its-variants-engineering-insights#147d9a33ecc9806090f3d5c749d31f05
lr_scheduler_type: constant
warmup_ratio: 0.03
# GRPO specific parameters
beta: 0.001 # 0.04 as in the deepseek math paper 0.001 from https://hijkzzz.notion.site/unraveling-rlhf-and-its-variants-engineering-insights#147d9a33ecc9806090f3d5c749d31f05
max_prompt_length: 4096
max_completion_length: 2048
num_iterations: 3
num_generations: 8
temperature: 1.0
top_p: 1.0
top_k: 100
min_p: 0.01
repetition_penalty: 1.1
use_vllm: true
# vllm_device: "cuda:3"
vllm_gpu_memory_utilization: 0.8
reward_funcs:
  - accuracy
  - format
  - length
reward_weights: [1.0, 1.0, 1.0]

# Logging arguments
log_level: info
logging_first_step: true
log_completions: true
logging_strategy: steps
logging_steps: 5
report_to:
  - tensorboard
save_strategy: "no"
save_steps: 200
save_total_limit: 3
save_only_model: true
seed: 42
# wandb_entity: grpo
# wandb_project: countdown-grpo-qwen2.5-3b-base

# Hugging Face Hub 
push_to_hub: false
hub_model_id: qwen2.5-3b_base-countdown-grpo # if not defined same as output_dir
hub_strategy: every_save

